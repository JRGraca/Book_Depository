{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "wishlist = pd.read_csv('wishlist.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Notes' in wishlist:\n",
    "\twishlist.drop(columns='Notes', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping... 9780751565355\n",
      "Sleeping for 4 seconds...\n",
      "Scraping... 9780929712697\n",
      "Sleeping for 5 seconds...\n",
      "Scraping... 9780929712376\n",
      "Sleeping for 3 seconds...\n",
      "Scraping... 9780874179880\n",
      "Sleeping for 5 seconds...\n",
      "Scraping... 9781471156267\n",
      "Sleeping for 4 seconds...\n",
      "Scraping... 9780062456786\n",
      "Sleeping for 4 seconds...\n",
      "Scraping... 9780990001638\n",
      "Sleeping for 3 seconds...\n"
     ]
    }
   ],
   "source": [
    "#BOOK DEPOSITORY\n",
    "\n",
    "#Since I'm assuming the input is a Book Depository wishlist, I don't include error handling for the case in which the book might not exist in the database.\n",
    "#As I write this, I realize I probably should, because of Murphy's Law, but this code will only be valid for a few weeks, anyway, so nah\n",
    "\n",
    "price_list_bd = []\n",
    "\n",
    "for item in wishlist['ISBN']:\n",
    "    url = r'https://www.bookdepository.com/isbn/' + str(item)\n",
    "    print(\"Scraping... \" + str(item))\n",
    "    html = rq.get(url)\n",
    "    if html.status_code != 200:\n",
    "        print(\"Page not read\")\n",
    "        break\n",
    "    else:\n",
    "        soup = BeautifulSoup(html.content)\n",
    "        test_if_there_is_price = soup.find(\"span\", class_ = \"sale-price\")\n",
    "        if test_if_there_is_price is None: #There is no \"sale-price\" class - this means the book is out of stock\n",
    "            price = np.nan\n",
    "        else: #Otherwise, finds the price and processes it to convert it to a numeric value. Assumes price is in €uros\n",
    "            price_string = soup.find(\"span\", class_ = \"sale-price\").text\n",
    "            price = float(price_string.replace(\",\", \".\")[:-2])\n",
    "    price_list_bd.append(price)\n",
    "    time_to_sleep = randint(1,6)\n",
    "    print(\"Sleeping for \" + str(time_to_sleep) + \" seconds...\")\n",
    "    sleep(time_to_sleep)\n",
    "wishlist['Price_BD'] = pd.Series(price_list_bd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping... 9780751565355\n",
      "Sleeping for 4 seconds...\n",
      "Scraping... 9780929712697\n",
      "Sleeping for 5 seconds...\n",
      "Scraping... 9780929712376\n",
      "Sleeping for 3 seconds...\n",
      "Scraping... 9780874179880\n",
      "Sleeping for 2 seconds...\n",
      "Scraping... 9781471156267\n",
      "Sleeping for 5 seconds...\n",
      "Scraping... 9780062456786\n",
      "Sleeping for 1 seconds...\n",
      "Scraping... 9780990001638\n",
      "Sleeping for 6 seconds...\n"
     ]
    }
   ],
   "source": [
    "#BLACKWELL'S\n",
    "\n",
    "price_list = []\n",
    "\n",
    "for item in wishlist['ISBN']:\n",
    "    url = 'https://blackwells.co.uk/bookshop/product/' + str(item)\n",
    "    print(\"Scraping... \" + str(item))\n",
    "    html = rq.get(url)\n",
    "    if html.status_code != 200: # Status code different from 200 means request was not successful\n",
    "        print(f\"Page not read - {item}\")\n",
    "        price = np.nan\n",
    "    else:\n",
    "        soup = BeautifulSoup(html.content)\n",
    "        if soup.find_all(string=\"Not available for sale\") == []: #If the book is available for sale, the string will not exist, so we can check the price\n",
    "            price_string = soup.find(\"li\", class_=\"product-price--current\")\n",
    "            #The site will generate pages based on any valid isbn you write, however, if they don't have it in the database the page will be blank.\n",
    "            #In that case, the string test above will not show a problem, so we have to test if the <li> tag actually exists (ie, the book exists in the database)\n",
    "            if price_string is None: \n",
    "                price = np.nan\n",
    "                print(f\"Book not in catalogue - \" + str(item))\n",
    "            else: #When the book exists in the database, this will process the price to a useful format. Assumes price is in €uros\n",
    "                price = float(price_string.text.strip().replace(\",\", \".\")[:-1])\n",
    "        else: #Book in catalogue, but out of stock\n",
    "            price = np.nan\n",
    "    price_list.append(price)\n",
    "    time_to_sleep = randint(1,6)\n",
    "    print(\"Sleeping for \" + str(time_to_sleep) + \" seconds...\")\n",
    "    sleep(time_to_sleep)\n",
    "wishlist['Price_BW'] = pd.Series(price_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create two tables, one for each bookshop. In each of those tables are all books which are cheaper in that particular bookshop and\n",
    "#all books which are not available in the other bookshop, sorted by price (cheapest first)\n",
    "\n",
    "BW_books = wishlist[(wishlist['Price_BW'] < wishlist['Price_BD']) | (wishlist['Price_BD'].isna())].sort_values(by='Price_BW')\n",
    "\n",
    "BD_books = wishlist[(wishlist['Price_BW'] > wishlist['Price_BD']) | (wishlist['Price_BW'].isna())].sort_values(by='Price_BD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended book to buy at Blackwell's is It Ends With Us: The most heartbreaking novel you'll ever read by Colleen Hoover, ISBN 9781471156267 for €10.79\n",
      "Recommended book to buy at the Book Depository is Harry Potter and the Cursed Child - Parts I & II by J. K. Rowling, ISBN 9780751565355 for €19.06\n"
     ]
    }
   ],
   "source": [
    "#This prints out the recommendation of what books to buy\n",
    "\n",
    "print(f'Recommended book to buy at Blackwell\\'s is {BW_books.iloc[0][2]} by {BW_books.iloc[0][3]}, ISBN {BW_books.iloc[0][1]} for €{BW_books.iloc[0][5]}')\n",
    "\n",
    "print(f'Recommended book to buy at the Book Depository is {BD_books.iloc[0][2]} by {BD_books.iloc[0][3]}, ISBN {BD_books.iloc[0][1]} for €{BD_books.iloc[0][4]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1c3fac89d3c1309bfce75e8d0a6d88b6f98de60557d5fab5a0078d3592abfe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
